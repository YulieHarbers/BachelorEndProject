{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "71b26f064e72d127"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from scipy.stats import pearsonr\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pointbiserialr, shapiro, levene\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "shap.initjs()\n",
    "df = pd.read_csv(r'C:\\Users\\20223868\\OneDrive - TU Eindhoven\\Documents\\School\\year 3\\BEP\\code\\output_combined_cleaned.csv')"
   ],
   "id": "cbee57b155de1b58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df.columns.tolist())",
   "id": "88ce98d30b93dc6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df = pd.read_csv(r'C:\\Users\\20223868\\OneDrive - TU Eindhoven\\Documents\\School\\year 3\\BEP\\code\\output_combined_cleaned.csv')\n",
    "df= df[[  'MeanHR_3_prev_diff_3',\n",
    "    'RMSSD_3_mean_diff_3',\n",
    " 'MeanNN_3_mean_diff_3',\n",
    " 'SDNN_3_mean_diff_3',\n",
    " 'SDRMSSD_3_mean_diff_3',\n",
    " 'LF/HF_3_mean_diff_3',\n",
    "    'AU01_interaction_mean', 'AU01_interaction_std', 'AU02_interaction_mean', 'AU02_interaction_std', 'AU04_interaction_mean', 'AU04_interaction_std', 'AU05_interaction_mean', 'AU05_interaction_std', 'AU06_interaction_mean', 'AU06_interaction_std', 'AU07_interaction_mean', 'AU07_interaction_std', 'AU09_interaction_mean', 'AU09_interaction_std', 'AU10_interaction_mean', 'AU10_interaction_std', 'AU12_interaction_mean', 'AU12_interaction_std', 'AU14_interaction_mean', 'AU14_interaction_std', 'AU15_interaction_mean', 'AU15_interaction_std', 'AU17_interaction_mean', 'AU17_interaction_std', 'AU20_interaction_mean', 'AU20_interaction_std', 'AU23_interaction_mean', 'AU23_interaction_std', 'AU25_interaction_mean', 'AU25_interaction_std', 'AU26_interaction_mean', 'AU26_interaction_std', 'AU45_interaction_mean', 'AU45_interaction_std', \"labels\"]]\n",
    "df_au = df[['AU01_interaction_mean', 'AU01_interaction_std', 'AU02_interaction_mean', 'AU02_interaction_std', 'AU04_interaction_mean', 'AU04_interaction_std', 'AU05_interaction_mean', 'AU05_interaction_std', 'AU06_interaction_mean', 'AU06_interaction_std', 'AU07_interaction_mean', 'AU07_interaction_std', 'AU09_interaction_mean', 'AU09_interaction_std', 'AU10_interaction_mean', 'AU10_interaction_std', 'AU12_interaction_mean', 'AU12_interaction_std', 'AU14_interaction_mean', 'AU14_interaction_std', 'AU15_interaction_mean', 'AU15_interaction_std', 'AU17_interaction_mean', 'AU17_interaction_std', 'AU20_interaction_mean', 'AU20_interaction_std', 'AU23_interaction_mean', 'AU23_interaction_std', 'AU25_interaction_mean', 'AU25_interaction_std', 'AU26_interaction_mean', 'AU26_interaction_std', 'AU45_interaction_mean', 'AU45_interaction_std', \"labels\"]]\n",
    "\n",
    "df_hrv = df.drop(['AU01_interaction_mean', 'AU01_interaction_std', 'AU02_interaction_mean', 'AU02_interaction_std', 'AU04_interaction_mean', 'AU04_interaction_std', 'AU05_interaction_mean', 'AU05_interaction_std', 'AU06_interaction_mean', 'AU06_interaction_std', 'AU07_interaction_mean', 'AU07_interaction_std', 'AU09_interaction_mean', 'AU09_interaction_std', 'AU10_interaction_mean', 'AU10_interaction_std', 'AU12_interaction_mean', 'AU12_interaction_std', 'AU14_interaction_mean', 'AU14_interaction_std', 'AU15_interaction_mean', 'AU15_interaction_std', 'AU17_interaction_mean', 'AU17_interaction_std', 'AU20_interaction_mean', 'AU20_interaction_std', 'AU23_interaction_mean', 'AU23_interaction_std', 'AU25_interaction_mean', 'AU25_interaction_std', 'AU26_interaction_mean', 'AU26_interaction_std', 'AU45_interaction_mean', 'AU45_interaction_std'],axis=1)"
   ],
   "id": "df5c7760ada17aa4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#force plot\n",
    "df = pd.read_csv(r'C:\\Users\\20223868\\OneDrive - TU Eindhoven\\Documents\\School\\year 3\\BEP\\code\\output_combined_cleaned.csv')\n",
    "features = [\n",
    "    'participant', 'MeanHR_3_prev_diff_3', 'RMSSD_3_mean_diff_3', 'MeanNN_3_mean_diff_3',\n",
    "    'SDNN_3_mean_diff_3', 'SDRMSSD_3_mean_diff_3', 'LF/HF_3_mean_diff_3',\n",
    "    'AU01_interaction_mean', 'AU01_interaction_std', 'AU02_interaction_mean', 'AU02_interaction_std',\n",
    "    'AU04_interaction_mean', 'AU04_interaction_std', 'AU05_interaction_mean', 'AU05_interaction_std',\n",
    "    'AU06_interaction_mean', 'AU06_interaction_std', 'AU07_interaction_mean', 'AU07_interaction_std',\n",
    "    'AU09_interaction_mean', 'AU09_interaction_std', 'AU10_interaction_mean', 'AU10_interaction_std',\n",
    "    'AU12_interaction_mean', 'AU12_interaction_std', 'AU14_interaction_mean', 'AU14_interaction_std',\n",
    "    'AU15_interaction_mean', 'AU15_interaction_std', 'AU17_interaction_mean', 'AU17_interaction_std',\n",
    "    'AU20_interaction_mean', 'AU20_interaction_std', 'AU23_interaction_mean', 'AU23_interaction_std',\n",
    "    'AU25_interaction_mean', 'AU25_interaction_std', 'AU26_interaction_mean', 'AU26_interaction_std',\n",
    "    'AU45_interaction_mean', 'AU45_interaction_std', 'labels'\n",
    "]\n",
    "df = df[features]\n",
    "\n",
    "X = df.drop(columns=['labels'])\n",
    "y = df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.drop(columns=['participant']), y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = GradientBoostingClassifier(learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "\n",
    "# SHAP values for all data except participant\n",
    "X_no_pid = X.drop(columns=['participant'])\n",
    "shap_values = explainer(X_no_pid)\n",
    "\n",
    "# Prepare DataFrame with shap values and participant ID\n",
    "shap_df = pd.DataFrame(shap_values.values, columns=X_no_pid.columns)\n",
    "shap_df['participant'] = X['participant'].values\n",
    "\n",
    "# Group by participant\n",
    "participant_shap = shap_df.groupby('participant').mean()\n",
    "participant_features = X.groupby('participant').mean()\n",
    "\n",
    "def plot_top_shap(pid, top_k=4):\n",
    "    shap_vals = participant_shap.loc[pid].values\n",
    "    feature_vals = participant_features.loc[pid].values\n",
    "    feature_names = participant_features.columns\n",
    "\n",
    "    top_indices = np.argsort(np.abs(shap_vals))[-top_k:]\n",
    "\n",
    "    shap.force_plot(\n",
    "        base_value=shap_values.base_values.mean(),\n",
    "        shap_values=shap_vals[top_indices],\n",
    "        features=feature_vals[top_indices],\n",
    "        feature_names=feature_names[top_indices],\n",
    "        matplotlib=True  # default\n",
    "    )\n",
    "\n",
    "plot_top_shap(pid=30, top_k=10)\n",
    "plot_top_shap(pid=70, top_k=10)"
   ],
   "id": "8981cdcfdf79e4f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#split df data\n",
    "x = df.drop('labels',axis=1)\n",
    "y = df['labels']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "x_hrv = df_hrv.drop('labels',axis=1)\n",
    "y_hrv = df_hrv['labels']\n",
    "x_hrv_train, x_hrv_test, y_hrv_train, y_hrv_test = train_test_split(x_hrv, y_hrv, test_size=0.20, random_state=42)\n",
    "\n",
    "x_au = df_au.drop('labels',axis=1)\n",
    "y_au = df_au['labels']\n",
    "x_au_train, x_au_test, y_au_train, y_au_test = train_test_split(x_au, y_au, test_size=0.20, random_state=42)"
   ],
   "id": "f50d42453279a85e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# correlation matrix\n",
    "cols = df.columns\n",
    "n = len(cols)\n",
    "\n",
    "corr_matrix = pd.DataFrame(np.zeros((n, n)), columns=cols, index=cols)\n",
    "pval_matrix = pd.DataFrame(np.zeros((n, n)), columns=cols, index=cols)\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i <= j:\n",
    "            corr, pval = pearsonr(df[cols[i]], df[cols[j]])\n",
    "            corr_matrix.iloc[i, j] = corr\n",
    "            corr_matrix.iloc[j, i] = corr\n",
    "            pval_matrix.iloc[i, j] = pval\n",
    "            pval_matrix.iloc[j, i] = pval\n",
    "\n",
    "print(\"Correlation Matrix:\\n\", corr_matrix)\n",
    "print(\"\\nP-Value Matrix:\\n\", pval_matrix)\n"
   ],
   "id": "885637a452409059",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "if 'labels' not in df.columns:\n",
    "    raise ValueError(\"Column 'labels' not found in DataFrame\")\n",
    "if not set(df['labels'].unique()).issubset({0, 1}):\n",
    "    raise ValueError(\"Column 'labels' must be binary (0 and 1)\")\n",
    "results = []\n",
    "for col in df.columns:\n",
    "    if col != 'labels':\n",
    "        group0 = df[df['labels'] == 0][col].dropna()\n",
    "        group1 = df[df['labels'] == 1][col].dropna()\n",
    "        corr, pval_corr = pointbiserialr(df[col], df['labels'])\n",
    "        stat0, pval_shapiro0 = shapiro(group0) if len(group0) >= 3 else (None, None)\n",
    "        stat1, pval_shapiro1 = shapiro(group1) if len(group1) >= 3 else (None, None)\n",
    "        stat_levene, pval_levene = levene(group0, group1)\n",
    "\n",
    "        results.append({\n",
    "            'Variable': col,\n",
    "            'Point-Biserial Corr': corr,\n",
    "            'Correlation p-value': pval_corr,\n",
    "            'Group0 Shapiro p-value': pval_shapiro0,\n",
    "            'Group1 Shapiro p-value': pval_shapiro1,\n",
    "            'Levene p-value': pval_levene,\n",
    "            'Normality Assumption Met': (pval_shapiro0 is not None and pval_shapiro0 > 0.05) and\n",
    "                                       (pval_shapiro1 is not None and pval_shapiro1 > 0.05),\n",
    "            'Equal Variance Assumption Met': pval_levene > 0.05,\n",
    "            'Significant Correlation (p<0.05)': pval_corr < 0.05\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('pointbiserial_correlation_with_assumptions.csv', index=False)\n"
   ],
   "id": "7a57c66fc745b2b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# rank biserial correlation\n",
    "binary_cols = [col for col in df.columns if set(df[col].dropna().unique()).issubset({0, 1})]\n",
    "other_cols = [col for col in df.columns if col not in binary_cols]\n",
    "results = []\n",
    "for bcol in binary_cols:\n",
    "    for ocol in other_cols:\n",
    "        group0 = df[df[bcol] == 0][ocol].dropna()\n",
    "        group1 = df[df[bcol] == 1][ocol].dropna()\n",
    "\n",
    "        if len(group0) > 0 and len(group1) > 0:\n",
    "            u_stat, pval = mannwhitneyu(group0, group1, alternative='two-sided')\n",
    "            r_rb = 1 - (2 * u_stat) / (len(group0) * len(group1))\n",
    "            results.append({\n",
    "                'Binary Label': bcol,\n",
    "                'Variable': ocol,\n",
    "                'Rank-Biserial Corr': r_rb,\n",
    "                'Significant (p < 0.05)': 'Yes' if pval < 0.05 else 'No'\n",
    "            })\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('rankbiserial_results.csv', index=False)\n"
   ],
   "id": "4de4a49e326b4ba8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "35ab4099c1d03470",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Confusion matrix of best model, see below\n",
    "confusion_matrix = np.array([[41, 28],\n",
    "                             [28, 71]])\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=['Actual Negative (0)', 'Actual Positive (1)'],\n",
    "                     columns=['Predicted Negative (0)', 'Predicted Positive (1)'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(df_cm)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix: GradientBoostingClassifier\")\n",
    "plt.show()\n"
   ],
   "id": "740575308e9d3da3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "threshold = 0.8\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "            pair = (cols[i], cols[j], corr_matrix.iloc[i, j], pval_matrix.iloc[i, j])\n",
    "            high_corr_pairs.append(pair)\n",
    "\n",
    "\n",
    "print(\"Highly Correlated Pairs (|correlation| > 0.8):\")\n",
    "for col1, col2, corr, pval in high_corr_pairs:\n",
    "    print(f\"{col1} - {col2}: correlation = {corr:.3f}, p-value = {pval:.3e}\")\n"
   ],
   "id": "98261d146ad1ed6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# FAU+HRV without class weights\n",
    "specificity = make_scorer(recall_score, pos_label=0)\n",
    "\n",
    "models = [\n",
    "    SVC(C= 1000, gamma= 0.01, kernel = \"rbf\"),\n",
    "    LogisticRegression(C=100,max_iter=1000, penalty= 'l2'),\n",
    "    GradientBoostingClassifier(learning_rate= 0.1, max_depth= 5, n_estimators= 200, subsample=0.8),\n",
    "    RandomForestClassifier(n_estimators=100, min_samples_split=2, max_depth= None),\n",
    "]\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'recall0': specificity\n",
    "}\n",
    "\n",
    "for model in models:\n",
    "    pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "    scores = cross_validate(pipe, x_train, y_train, cv=5, scoring=scoring)\n",
    "    print(f\"\\n{model.__class__.__name__}:\")\n",
    "    for metric in scoring:\n",
    "        mean = np.mean(scores[f'test_{metric}']) * 100\n",
    "        std = np.std(scores[f'test_{metric}']) * 100\n",
    "        print(f\"{metric.capitalize():<10} = {mean:.2f}% (+/- {std:.2f}%)\")\n",
    "    pipe.fit(x_train, y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall (Sensitivity): {recall_score(y_test, y_pred) * 100:.2f}%\")  # Class 1\n",
    "    print(f\"F1-Score: {f1_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall (Class 0): {recall_score(y_test, y_pred, pos_label=0) * 100:.2f}%\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix: {model.__class__.__name__}\")\n",
    "    plt.show()"
   ],
   "id": "9ad1e8759fff8d31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# FAU+HRV with class weights\n",
    "\n",
    "\n",
    "specificity = make_scorer(recall_score, pos_label=0)\n",
    "\n",
    "models = [\n",
    "    SVC(class_weight = \"balanced\", C= 1000, gamma= 0.01, kernel = \"rbf\"),\n",
    "    LogisticRegression(class_weight = \"balanced\", C=100,max_iter=1000, penalty= 'l2'),\n",
    "    GradientBoostingClassifier(learning_rate= 0.1, max_depth= 5, n_estimators= 200, subsample=0.8),\n",
    "    RandomForestClassifier(class_weight = \"balanced\", n_estimators=300, min_samples_split=10, max_depth= 20),\n",
    "]\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'recall0': specificity\n",
    "}\n",
    "\n",
    "for model in models:\n",
    "    pipe = make_pipeline(StandardScaler(), model)\n",
    "    if isinstance(model, GradientBoostingClassifier):\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "        scores = cross_validate(pipe, x_train, y_train, cv=5, scoring=scoring, fit_params={'gradientboostingclassifier__sample_weight': sample_weights})\n",
    "    else:\n",
    "        scores = cross_validate(pipe, x_train, y_train, cv=5, scoring=scoring)\n",
    "    print(f\"\\n{model.__class__.__name__}:\")\n",
    "    for metric in scoring:\n",
    "        mean = np.mean(scores[f'test_{metric}']) * 100\n",
    "        std = np.std(scores[f'test_{metric}']) * 100\n",
    "        print(f\"{metric.capitalize():<10} = {mean:.2f}% (+/- {std:.2f}%)\")\n",
    "    pipe.fit(x_train, y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall (Sensitivity): {recall_score(y_test, y_pred) * 100:.2f}%\")  # Class 1\n",
    "    print(f\"F1-Score: {f1_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall (Class 0): {recall_score(y_test, y_pred, pos_label=0) * 100:.2f}%\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix: {model.__class__.__name__}\")\n",
    "    plt.show()"
   ],
   "id": "53b077b2c9c9c0a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# shap\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "model = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 5, n_estimators= 200, subsample=0.8\n",
    ")\n",
    "# rename HRV feature names e.g. RMSSD_3_mean_diff_3 to 'RMSSD' to make it more understandable\n",
    "model.fit(x_train, y_train)\n",
    "feature_names = [\n",
    "'MeanHR_3_prev_diff_3', 'RMSSD', 'MeanNN', 'SDNN', 'SDRMSSD', 'LF/HF', 'AU01_interaction_mean', 'AU01_interaction_std', 'AU02_interaction_mean', 'AU02_interaction_std', 'AU04_interaction_mean', 'AU04_interaction_std', 'AU05_interaction_mean', 'AU05_interaction_std', 'AU06_interaction_mean', 'AU06_interaction_std', 'AU07_interaction_mean', 'AU07_interaction_std', 'AU09_interaction_mean', 'AU09_interaction_std', 'AU10_interaction_mean', 'AU10_interaction_std', 'AU12_interaction_mean', 'AU12_interaction_std', 'AU14_interaction_mean', 'AU14_interaction_std', 'AU15_interaction_mean', 'AU15_interaction_std', 'AU17_interaction_mean', 'AU17_interaction_std', 'AU20_interaction_mean', 'AU20_interaction_std', 'AU23_interaction_mean', 'AU23_interaction_std', 'AU25_interaction_mean', 'AU25_interaction_std', 'AU26_interaction_mean', 'AU26_interaction_std', 'AU45_interaction_mean', 'AU45_interaction_std'\n",
    "]\n",
    "\n",
    "x_test_renamed = x_test.copy()\n",
    "x_test_renamed.columns = feature_names\n",
    "explainer = shap.Explainer(model, x_test_renamed)\n",
    "shap_values = explainer(x_test_renamed)\n",
    "shap.summary_plot(shap_values, x_test_renamed)\n",
    "shap.plots.bar(shap_values)\n"
   ],
   "id": "6e95cdb24073f151",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# parameter tuning for HRV+AU for specificity\n",
    "\n",
    "\n",
    "specificity = make_scorer(recall_score, pos_label=0)\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth': [None,5, 10, 20],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "model = RandomForestClassifier(class_weight=\"balanced\")\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "search = RandomizedSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "search.fit(x_train, y_train)\n",
    "print(\"Best parameters: randomforest\", search.best_params_)\n",
    "print(\"Best specificity score: randomforest\", search.best_score_)\n",
    "\n",
    "param_grid = {'svc__C': [0.1, 1, 10, 100, 1000],\n",
    "\t\t\t'svc__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "\t\t\t'svc__kernel': ['rbf']}\n",
    "model = SVC(class_weight=\"balanced\")\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Best parameters: svc\", grid.best_params_)\n",
    "print(\"Best accuracy score: svc\", grid.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute sample weights (like class_weight='balanced')\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'gradientboostingclassifier__n_estimators': [100, 200],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1],\n",
    "    'gradientboostingclassifier__max_depth': [3, 5, 7],\n",
    "    'gradientboostingclassifier__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "# Pass sample weights via fit_params\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "grid.fit(x_train, y_train, gradientboostingclassifier__sample_weight=sample_weights)\n",
    "\n",
    "print(\"Best parameters: gradientboostingclassifier\", grid.best_params_)\n",
    "print(\"Best specificity score: gradientboostingclassifier\", grid.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__C': [1, 10, 100, 1000]}\n",
    "model = LogisticRegression(class_weight=\"balanced\",max_iter=1000)\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Best parameters: logistic regression\", grid.best_params_)\n",
    "print(\"Best accuracy score: logistic regression\", grid.best_score_)\n"
   ],
   "id": "85640b92b0eafb02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# parameter tuning for HRV+AU for accuracy\n",
    "\n",
    "\n",
    "#random forest\n",
    "specificity = make_scorer(recall_score, pos_label=0)\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth': [None,5, 10, 20],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "model = RandomForestClassifier(class_weight=\"balanced\")\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "search = RandomizedSearchCV(pipe, param_grid, scoring=\"accuracy\", cv=5)\n",
    "search.fit(x_train, y_train)\n",
    "print(\"Best parameters: randomforest\", search.best_params_)\n",
    "print(\"Best specificity score: randomforest\", search.best_score_)\n",
    "\n",
    "\n",
    "#SVC\n",
    "param_grid = {'svc__C': [0.1, 1, 10, 100, 1000],\n",
    "\t\t\t'svc__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "\t\t\t'svc__kernel': ['rbf']}\n",
    "model = SVC(class_weight=\"balanced\")\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=\"accuracy\", cv=5)\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Best parameters: svc\", grid.best_params_)\n",
    "print(\"Best accuracy score: svc\", grid.best_score_)\n",
    "\n",
    "\n",
    "#gradientboostingclassifier\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'gradientboostingclassifier__n_estimators': [100, 200],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1],\n",
    "    'gradientboostingclassifier__max_depth': [3, 5, 7],\n",
    "    'gradientboostingclassifier__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "# Pass sample weights via fit_params\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=\"accuracy\", cv=5)\n",
    "grid.fit(x_train, y_train, gradientboostingclassifier__sample_weight=sample_weights)\n",
    "\n",
    "print(\"Best parameters: gradientboostingclassifier\", grid.best_params_)\n",
    "print(\"Best specificity score: gradientboostingclassifier\", grid.best_score_)\n",
    "\n",
    "\n",
    "#logistic regression\n",
    "param_grid = {'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__C': [1, 10, 100, 1000]}\n",
    "model = LogisticRegression(class_weight=\"balanced\",max_iter=1000)\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=\"accuracy\", cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Best parameters: logistic regression\", grid.best_params_)\n",
    "print(\"Best accuracy score: logistic regression\", grid.best_score_)\n"
   ],
   "id": "30b6a6852058aaf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# parameter tuning for HRV for specificity\n",
    "\n",
    "\n",
    "specificity = make_scorer(recall_score, pos_label=0)\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth': [None,5, 10, 20],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "search = RandomizedSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "search.fit(x_hrv_train, y_hrv_train)\n",
    "print(\"Best parameters: randomforest\", search.best_params_)\n",
    "print(\"Best specificity score: randomforest\", search.best_score_)\n",
    "\n",
    "param_grid = {'svc__C': [0.1, 1, 10, 100, 1000],\n",
    "\t\t\t'svc__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "\t\t\t'svc__kernel': ['rbf']}\n",
    "model = SVC(class_weight='balanced')  # Auto adjust weights inversely proportional to class frequencies\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "\n",
    "grid.fit(x_hrv_train, y_hrv_train)\n",
    "print(\"Best parameters: svc\", grid.best_params_)\n",
    "print(\"Best accuracy score: svc\", grid.best_score_)\n",
    "\n",
    "\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "param_grid = {\n",
    "    'gradientboostingclassifier__n_estimators': [100, 200],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1],\n",
    "    'gradientboostingclassifier__max_depth': [3, 5, 7],\n",
    "    'gradientboostingclassifier__subsample': [0.8, 1.0]\n",
    "}\n",
    "model = GradientBoostingClassifier()\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "grid.fit(x_hrv_train, y_hrv_train, gradientboostingclassifier__sample_weight=sample_weights)\n",
    "print(\"Best parameters: gradientboostingclassifier\", grid.best_params_)\n",
    "print(\"Best accuracy score: gradientboostingclassifier\", grid.best_score_)\n",
    "\n",
    "param_grid = {'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__C': [1, 10, 100, 1000]}\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "grid.fit(x_hrv_train, y_hrv_train)\n",
    "print(\"Best parameters: logistic regression\", grid.best_params_)\n",
    "print(\"Best accuracy score: logistic regression\", grid.best_score_)\n"
   ],
   "id": "c87fec0df176a225",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# parameter tuning for AU for specificity\n",
    "\n",
    "\n",
    "specificity = make_scorer(recall_score, pos_label=0)\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth': [None,5, 10, 20],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "search = RandomizedSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "search.fit(x_au_train, y_au_train)\n",
    "print(\"Best parameters: randomforest\", search.best_params_)\n",
    "print(\"Best specificity score: randomforest\", search.best_score_)\n",
    "\n",
    "param_grid = {'svc__C': [0.1, 1, 10, 100, 1000],\n",
    "\t\t\t'svc__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "\t\t\t'svc__kernel': ['rbf']}\n",
    "model = SVC(class_weight='balanced')\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "\n",
    "grid.fit(x_au_train, y_au_train)\n",
    "print(\"Best parameters: svc\", grid.best_params_)\n",
    "print(\"Best accuracy score: svc\", grid.best_score_)\n",
    "\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "param_grid = {\n",
    "    'gradientboostingclassifier__n_estimators': [100, 200],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1],\n",
    "    'gradientboostingclassifier__max_depth': [3, 5, 7],\n",
    "    'gradientboostingclassifier__subsample': [0.8, 1.0]\n",
    "}\n",
    "model = GradientBoostingClassifier()\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "grid.fit(x_au_train, y_au_train, gradientboostingclassifier__sample_weight=sample_weights )\n",
    "print(\"Best parameters: gradientboostingclassifier\", grid.best_params_)\n",
    "print(\"Best accuracy score: gradientboostingclassifier\", grid.best_score_)\n",
    "\n",
    "param_grid = {'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__C': [1, 10, 100, 1000]}\n",
    "model = LogisticRegression(class_weight='balanced',max_iter=1000)\n",
    "pipe = make_pipeline(StandardScaler(), model)\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=specificity, cv=5)\n",
    "grid.fit(x_au_train, y_au_train)\n",
    "print(\"Best parameters: logistic regression\", grid.best_params_)\n",
    "print(\"Best accuracy score: logistic regression\", grid.best_score_)\n"
   ],
   "id": "12edf69936ab19a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#HRV\n",
    "\n",
    "specificity = make_scorer(recall_score, pos_label=0)\n",
    "\n",
    "models = [\n",
    "    SVC(C=1000, gamma=0.1, kernel='rbf', class_weight='balanced'),\n",
    "    LogisticRegression(C=1, penalty=\"l2\",max_iter=1000, class_weight='balanced'),\n",
    "    GradientBoostingClassifier(learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8),  # no class_weight param\n",
    "    RandomForestClassifier(n_estimators=300, min_samples_split=2, max_depth=20, class_weight='balanced'),\n",
    "]\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'recall0': specificity\n",
    "}\n",
    "\n",
    "for model in models:\n",
    "    pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "    if isinstance(model, GradientBoostingClassifier):\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y_hrv_train)\n",
    "        pipe.fit(x_hrv_train, y_hrv_train, gradientboostingclassifier__sample_weight=sample_weights)\n",
    "\n",
    "        y_hrv_pred = pipe.predict(x_hrv_test)\n",
    "\n",
    "        print(f\"\\n{model.__class__.__name__} (with sample_weight):\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"Precision: {precision_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"Recall (Sensitivity): {recall_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"F1-Score: {f1_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"ROC AUC: {roc_auc_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"Recall (Class 0): {recall_score(y_hrv_test, y_hrv_pred, pos_label=0) * 100:.2f}%\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_hrv_test, y_hrv_pred))\n",
    "    else:\n",
    "        scores = cross_validate(pipe, x_hrv_train, y_hrv_train, cv=5, scoring=scoring)\n",
    "        print(f\"\\n{model.__class__.__name__}:\")\n",
    "        for metric in scoring:\n",
    "            mean = np.mean(scores[f'test_{metric}']) * 100\n",
    "            std = np.std(scores[f'test_{metric}']) * 100\n",
    "            print(f\"{metric.capitalize():<10} = {mean:.2f}% (+/- {std:.2f}%)\")\n",
    "        pipe.fit(x_hrv_train, y_hrv_train)\n",
    "        y_hrv_pred = pipe.predict(x_hrv_test)\n",
    "        print(f\"Accuracy: {accuracy_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"Precision: {precision_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"Recall (Sensitivity): {recall_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"F1-Score: {f1_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"ROC AUC: {roc_auc_score(y_hrv_test, y_hrv_pred) * 100:.2f}%\")\n",
    "        print(f\"Recall (Class 0): {recall_score(y_hrv_test, y_hrv_pred, pos_label=0) * 100:.2f}%\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_hrv_test, y_hrv_pred))\n"
   ],
   "id": "d513e280b0041905",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# AU\n",
    "\n",
    "specificity = make_scorer(recall_score, pos_label=0)\n",
    "\n",
    "models = [\n",
    "    SVC(class_weight = \"balanced\",C=100, gamma= 0.01, kernel= 'rbf'),\n",
    "    LogisticRegression(class_weight = \"balanced\", C=100,max_iter=1000, penalty ='l2'),\n",
    "    GradientBoostingClassifier(learning_rate= 0.01, max_depth= 3, n_estimators= 200, subsample=0.8),\n",
    "    RandomForestClassifier(class_weight = \"balanced\", n_estimators=100, min_samples_split=10, max_depth= 5),\n",
    "\n",
    "]\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'recall0': specificity\n",
    "}\n",
    "\n",
    "for model in models:\n",
    "    pipe = make_pipeline(StandardScaler(), model)\n",
    "    if isinstance(model, GradientBoostingClassifier):\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y_au_train)\n",
    "        scores = cross_validate(pipe, x_au_train, y_au_train, cv=5, scoring=scoring, fit_params={'gradientboostingclassifier__sample_weight': sample_weights})\n",
    "    else:\n",
    "        scores = cross_validate(pipe, x_au_train, y_au_train, cv=5, scoring=scoring)\n",
    "    print(f\"\\n{model.__class__.__name__}:\")\n",
    "    for metric in scoring:\n",
    "        mean = np.mean(scores[f'test_{metric}']) * 100\n",
    "        std = np.std(scores[f'test_{metric}']) * 100\n",
    "        print(f\"{metric.capitalize():<10} = {mean:.2f}% (+/- {std:.2f}%)\")\n",
    "    pipe.fit(x_au_train, y_au_train)\n",
    "    y_au_pred = pipe.predict(x_au_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_au_test, y_au_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_au_test, y_au_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall (Sensitivity): {recall_score(y_au_test, y_au_pred) * 100:.2f}%\")  # Class 1\n",
    "    print(f\"F1-Score: {f1_score(y_au_test, y_au_pred) * 100:.2f}%\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_au_test, y_au_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall (Class 0): {recall_score(y_au_test, y_au_pred, pos_label=0) * 100:.2f}%\")\n",
    "    cm = confusion_matrix(y_au_test, y_au_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ],
   "id": "a62a84e4bf987f38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#search for interactions, SHAP dependency plots\n",
    "\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "# Train model\n",
    "model = GradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8\n",
    ")\n",
    "model.fit(x_train, y_train, sample_weight=sample_weights)\n",
    "model.fit(x_train, y_train)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "shap.dependence_plot(\"MeanNN_3_mean_diff_3\", shap_values, x_test)"
   ],
   "id": "cfa0730fcac64338",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
