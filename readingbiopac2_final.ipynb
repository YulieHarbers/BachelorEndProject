{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import bioread\n",
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyhrv\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "participants_selected = ['pp2', 'pp3', 'pp4', 'pp6', 'pp22', 'pp30', 'pp31', 'pp24', 'pp25', 'pp45', 'pp53', 'pp47', 'pp49', 'pp56', 'pp66', 'pp75', 'pp70', 'pp85', 'pp93', 'pp102', 'pp96', 'pp104', 'pp103', 'pp91', 'pp115', 'pp107', 'pp110', 'pp112', \"pp95\", \"pp97\"]\n"
   ],
   "id": "d960a0914b799c49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "duration_matrix = pd.read_csv(r\"C:\\Users\\20223868\\OneDrive - TU Eindhoven\\Documents\\School\\year 3\\BEP\\code\\durationtable.csv\")\n",
    "\n",
    "results1 = []\n",
    "results2 = []\n",
    "results3 = []"
   ],
   "id": "81fd9a415c2995c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results1 = []\n",
    "\n",
    "for participant in participants_selected:\n",
    "    acq_file_path = r\"C:\\Users\\20223868\\OneDrive - TU Eindhoven\\Documents\\School\\year 3\\BEP\\code\\wavescontrolled\\waves\\LOG\"+participant+\".acq\"\n",
    "    print(participant)\n",
    "    intervals = []\n",
    "    start_time = 0\n",
    "    durations = duration_matrix[participant].tolist()\n",
    "    for duration in durations:\n",
    "        end_time = start_time + duration\n",
    "        intervals.append((start_time, end_time))\n",
    "        start_time = end_time\n",
    "\n",
    "    # Read ECG data\n",
    "    ecg_channel_name = \"final ECG\"\n",
    "    file = bioread.read_file(acq_file_path)\n",
    "    channel = next(c for c in file.channels if ecg_channel_name in c.name)\n",
    "    ecg_data = channel.data\n",
    "    timestamps = channel.time_index\n",
    "    sampling_rate = channel.samples_per_second\n",
    "\n",
    "    videonr = 0\n",
    "    baseline_hr = None\n",
    "    prev_metrics = {}\n",
    "\n",
    "    interval_metrics = []\n",
    "\n",
    "    for start, end in intervals:\n",
    "        idx = np.where((timestamps >= start) & (timestamps < end))[0]\n",
    "\n",
    "        if len(idx) < int(sampling_rate * 5):\n",
    "            continue\n",
    "\n",
    "        segment = ecg_data[idx]\n",
    "        try:\n",
    "            signals, info = nk.ecg_process(segment, sampling_rate=sampling_rate)\n",
    "            heart_rate_series = signals[\"ECG_Rate\"]\n",
    "            mean_hr = heart_rate_series.mean()\n",
    "            rpeaks = info[\"ECG_R_Peaks\"]\n",
    "\n",
    "            if len(rpeaks) < 2:\n",
    "                continue\n",
    "\n",
    "            time_features = nk.hrv_time(rpeaks, sampling_rate=sampling_rate, show=False)\n",
    "\n",
    "            # Baseline\n",
    "            if baseline_hr is None:\n",
    "                baseline_hr = mean_hr\n",
    "                baseline_RMSSD = time_features.get(\"HRV_RMSSD\", [np.nan])[0]\n",
    "                baseline_SDSD = time_features.get(\"HRV_SDSD\", [np.nan])[0]\n",
    "                baseline_MeanNN = time_features.get(\"HRV_MeanNN\", [np.nan])[0]\n",
    "                baseline_MedianNN = time_features.get(\"HRV_MedianNN\", [np.nan])[0]\n",
    "                baseline_SDNN = time_features.get(\"HRV_SDNN\", [np.nan])[0]\n",
    "                baseline_SDRMSSD = time_features.get(\"HRV_SDRMSSD\", [np.nan])[0]\n",
    "\n",
    "            try:\n",
    "                welch_results = pyhrv.frequency_domain.welch_psd(rpeaks, show=False)\n",
    "                lf_hf_ratio_pyhrv = float(welch_results[\"fft_ratio\"])\n",
    "            except Exception as e:\n",
    "                lf_hf_ratio_pyhrv = np.nan\n",
    "\n",
    "            curr_metrics = {\n",
    "                \"RMSSD\": time_features.get(\"HRV_RMSSD\", [np.nan])[0],\n",
    "                \"SDSD\": time_features.get(\"HRV_SDSD\", [np.nan])[0],\n",
    "                \"MeanHR\": mean_hr,\n",
    "                \"MeanNN\": time_features.get(\"HRV_MeanNN\", [np.nan])[0],\n",
    "                \"MedianNN\": time_features.get(\"HRV_MedianNN\", [np.nan])[0],\n",
    "                \"SDNN\": time_features.get(\"HRV_SDNN\", [np.nan])[0],\n",
    "                \"SDRMSSD\": time_features.get(\"HRV_SDRMSSD\", [np.nan])[0],\n",
    "                \"LF/HF\": lf_hf_ratio_pyhrv,\n",
    "                \"CVNN\": time_features.get(\"HRV_CVNN\", [np.nan])[0],\n",
    "                \"CVSD\": time_features.get(\"HRV_CVSD\", [np.nan])[0],\n",
    "            }\n",
    "\n",
    "            # Baseline diff\n",
    "            curr_metrics[\"RMSSD_diff\"] = curr_metrics[\"RMSSD\"] - baseline_RMSSD\n",
    "            curr_metrics[\"SDSD_diff\"] = curr_metrics[\"SDSD\"] - baseline_SDSD\n",
    "            curr_metrics[\"MeanHR_diff\"] = curr_metrics[\"MeanHR\"] - baseline_hr\n",
    "            curr_metrics[\"MeanNN_diff\"] = curr_metrics[\"MeanNN\"] - baseline_MeanNN\n",
    "            curr_metrics[\"MedianNN_diff\"] = curr_metrics[\"MedianNN\"] - baseline_MedianNN\n",
    "            curr_metrics[\"SDNN_diff\"] = curr_metrics[\"SDNN\"] - baseline_SDNN\n",
    "            curr_metrics[\"SDRMSSD_diff\"] = curr_metrics[\"SDRMSSD\"] - baseline_SDRMSSD\n",
    "\n",
    "            base_metric_keys = [\"RMSSD\", \"SDSD\", \"MeanHR\", \"MeanNN\", \"MedianNN\", \"SDNN\", \"SDRMSSD\", \"LF/HF\", \"CVNN\", \"CVSD\"]\n",
    "\n",
    "            for k in base_metric_keys:\n",
    "                if k in prev_metrics and isinstance(curr_metrics[k], (int, float)) and isinstance(prev_metrics[k], (int, float)):\n",
    "                    curr_metrics[f\"{k}_prev_diff\"] = curr_metrics[k] - prev_metrics[k]\n",
    "                else:\n",
    "                    curr_metrics[f\"{k}_prev_diff\"] = 0\n",
    "\n",
    "\n",
    "            curr_metrics.update({\n",
    "                \"participant\": participant,\n",
    "                \"videonr\": videonr,\n",
    "                \"Start Time (s)\": start,\n",
    "                \"End Time (s)\": end\n",
    "            })\n",
    "\n",
    "            interval_metrics.append(curr_metrics)\n",
    "            prev_metrics = curr_metrics.copy()\n",
    "            print(videonr)\n",
    "            videonr += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed interval ({start}-{end}): {e}\")\n",
    "            continue\n",
    "    df = pd.DataFrame(interval_metrics)\n",
    "    feature_cols = [\"RMSSD\", \"SDSD\", \"MeanHR\", \"MeanNN\", \"MedianNN\", \"SDNN\", \"SDRMSSD\", \"LF/HF\", \"CVNN\", \"CVSD\"]\n",
    "\n",
    "    means = df[feature_cols].mean()\n",
    "    medians = df[feature_cols].median()\n",
    "\n",
    "    for m in interval_metrics:\n",
    "        for f in feature_cols:\n",
    "            m[f\"{f}_mean_diff\"] = m[f] - means[f]\n",
    "            m[f\"{f}_median_diff\"] = m[f] - medians[f]\n",
    "    print(means, medians)\n",
    "    results1.extend(interval_metrics)\n"
   ],
   "id": "8ed5313e565f1331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results2 = []\n",
    "\n",
    "for participant in participants_selected:\n",
    "    acq_file_path = r\"C:\\Users\\20223868\\OneDrive - TU Eindhoven\\Documents\\School\\year 3\\BEP\\code\\wavescontrolled\\waves\\LOG\"+participant+\".acq\"\n",
    "\n",
    "    intervals = []\n",
    "    start_time = 0\n",
    "    durations = duration_matrix[participant].tolist()\n",
    "\n",
    "    group_size = 3\n",
    "    for i in range(0, len(durations), group_size):\n",
    "        group = durations[i:i + group_size]\n",
    "        duration_sum = sum(group)\n",
    "        end_time = start_time + duration_sum\n",
    "        intervals.append((start_time, end_time))\n",
    "        start_time = end_time\n",
    "\n",
    "    # Read ECG data\n",
    "    ecg_channel_name = \"final ECG\"\n",
    "    file = bioread.read_file(acq_file_path)\n",
    "    channel = next(c for c in file.channels if ecg_channel_name in c.name)\n",
    "    ecg_data = channel.data\n",
    "    timestamps = channel.time_index\n",
    "    sampling_rate = channel.samples_per_second\n",
    "\n",
    "    videonr = 0\n",
    "    baseline_hr = None\n",
    "    prev_metrics = {}\n",
    "\n",
    "    interval_metrics = []\n",
    "\n",
    "    for start, end in intervals:\n",
    "        idx = np.where((timestamps >= start) & (timestamps < end))[0]\n",
    "\n",
    "        if len(idx) < int(sampling_rate * 5):\n",
    "            continue\n",
    "\n",
    "        segment = ecg_data[idx]\n",
    "        try:\n",
    "            signals, info = nk.ecg_process(segment, sampling_rate=sampling_rate)\n",
    "            heart_rate_series = signals[\"ECG_Rate\"]\n",
    "            mean_hr = heart_rate_series.mean()\n",
    "            rpeaks = info[\"ECG_R_Peaks\"]\n",
    "\n",
    "            if len(rpeaks) < 2:\n",
    "                continue\n",
    "\n",
    "            time_features = nk.hrv_time(rpeaks, sampling_rate=sampling_rate, show=False)\n",
    "\n",
    "            # Baseline\n",
    "            if baseline_hr is None:\n",
    "                baseline_hr = mean_hr\n",
    "                baseline_RMSSD = time_features.get(\"HRV_RMSSD\", [np.nan])[0]\n",
    "                baseline_SDSD = time_features.get(\"HRV_SDSD\", [np.nan])[0]\n",
    "                baseline_MeanNN = time_features.get(\"HRV_MeanNN\", [np.nan])[0]\n",
    "                baseline_MedianNN = time_features.get(\"HRV_MedianNN\", [np.nan])[0]\n",
    "                baseline_SDNN = time_features.get(\"HRV_SDNN\", [np.nan])[0]\n",
    "                baseline_SDRMSSD = time_features.get(\"HRV_SDRMSSD\", [np.nan])[0]\n",
    "\n",
    "            try:\n",
    "                welch_results = pyhrv.frequency_domain.welch_psd(rpeaks, show=False)\n",
    "                lf_hf_ratio_pyhrv = float(welch_results[\"fft_ratio\"])\n",
    "            except Exception as e:\n",
    "                lf_hf_ratio_pyhrv = np.nan\n",
    "\n",
    "            # Add _3 suffix to all metric keys:\n",
    "            curr_metrics = {\n",
    "                \"RMSSD_3\": time_features.get(\"HRV_RMSSD\", [np.nan])[0],\n",
    "                \"SDSD_3\": time_features.get(\"HRV_SDSD\", [np.nan])[0],\n",
    "                \"MeanHR_3\": mean_hr,\n",
    "                \"MeanNN_3\": time_features.get(\"HRV_MeanNN\", [np.nan])[0],\n",
    "                \"MedianNN_3\": time_features.get(\"HRV_MedianNN\", [np.nan])[0],\n",
    "                \"SDNN_3\": time_features.get(\"HRV_SDNN\", [np.nan])[0],\n",
    "                \"SDRMSSD_3\": time_features.get(\"HRV_SDRMSSD\", [np.nan])[0],\n",
    "                \"LF/HF_3\": lf_hf_ratio_pyhrv,\n",
    "                \"CVNN_3\": time_features.get(\"HRV_CVNN\", [np.nan])[0],\n",
    "                \"CVSD_3\": time_features.get(\"HRV_CVSD\", [np.nan])[0],\n",
    "            }\n",
    "            curr_metrics[\"RMSSD_diff_3\"] = curr_metrics[\"RMSSD_3\"] - baseline_RMSSD\n",
    "            curr_metrics[\"SDSD_diff_3\"] = curr_metrics[\"SDSD_3\"] - baseline_SDSD\n",
    "            curr_metrics[\"MeanHR_diff_3\"] = curr_metrics[\"MeanHR_3\"] - baseline_hr\n",
    "            curr_metrics[\"MeanNN_diff_3\"] = curr_metrics[\"MeanNN_3\"] - baseline_MeanNN\n",
    "            curr_metrics[\"MedianNN_diff_3\"] = curr_metrics[\"MedianNN_3\"] - baseline_MedianNN\n",
    "            curr_metrics[\"SDNN_diff_3\"] = curr_metrics[\"SDNN_3\"] - baseline_SDNN\n",
    "            curr_metrics[\"SDRMSSD_diff_3\"] = curr_metrics[\"SDRMSSD_3\"] - baseline_SDRMSSD\n",
    "            base_metric_keys = [\"RMSSD_3\", \"SDSD_3\", \"MeanHR_3\", \"MeanNN_3\", \"MedianNN_3\", \"SDNN_3\", \"SDRMSSD_3\", \"LF/HF_3\", \"CVNN_3\", \"CVSD_3\"]\n",
    "\n",
    "            for k in base_metric_keys:\n",
    "                if k in prev_metrics and isinstance(curr_metrics[k], (int, float)) and isinstance(prev_metrics[k], (int, float)):\n",
    "                    curr_metrics[f\"{k}_prev_diff_3\"] = curr_metrics[k] - prev_metrics[k]\n",
    "                else:\n",
    "                    curr_metrics[f\"{k}_prev_diff_3\"] = 0\n",
    "            for x in range(group_size):\n",
    "                print(videonr)\n",
    "                curr_metrics.update({\n",
    "                    \"participant\": participant,\n",
    "                    \"videonr\": videonr,\n",
    "                    \"Start Time (s)\": start,\n",
    "                    \"End Time (s)\": end\n",
    "                })\n",
    "                interval_metrics.append(curr_metrics.copy())\n",
    "                videonr += 1\n",
    "            prev_metrics = curr_metrics.copy()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed interval ({start}-{end}): {e}\")\n",
    "            continue\n",
    "    df = pd.DataFrame(interval_metrics)\n",
    "    feature_cols = [\"RMSSD_3\", \"SDSD_3\", \"MeanHR_3\", \"MeanNN_3\", \"MedianNN_3\", \"SDNN_3\", \"SDRMSSD_3\", \"LF/HF_3\", \"CVNN_3\", \"CVSD_3\"]\n",
    "\n",
    "    means = df[feature_cols].mean()\n",
    "    medians = df[feature_cols].median()\n",
    "\n",
    "    for m in interval_metrics:\n",
    "        for f in feature_cols:\n",
    "            m[f\"{f}_mean_diff_3\"] = m[f] - means[f]\n",
    "            m[f\"{f}_median_diff_3\"] = m[f] - medians[f]\n",
    "    results2.extend(interval_metrics)\n"
   ],
   "id": "145e64cd46bf2560",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(results2[:10])",
   "id": "cf94d3cf2c334485",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(results2[:10])",
   "id": "118359f3ca43a6ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "for participant in participants_selected:\n",
    "    intervals = []\n",
    "    durations = duration_matrix[participant].tolist()\n",
    "    start_time =0\n",
    "    group_size=6\n",
    "    for i in range(0, len(durations), group_size):\n",
    "        group = durations[i:i + group_size]\n",
    "        duration_sum = sum(group)\n",
    "        end_time = start_time + duration_sum\n",
    "        intervals.append((start_time, end_time))\n",
    "        start_time = end_time\n",
    "    print(intervals)\n",
    "    acq_file_path = r\"C:/Users/20223868\\OneDrive - TU Eindhoven\\Documents\\School\\year 3\\BEP\\code\\wavescontrolled\\waves\\LOG\"+participant+\".acq\"\n",
    "    ecg_channel_name = \"final ECG\"\n",
    "    file = bioread.read_file(acq_file_path)\n",
    "    channel = next(c for c in file.channels if ecg_channel_name in c.name)\n",
    "    ecg_data = channel.data\n",
    "    timestamps = channel.time_index\n",
    "    sampling_rate = channel.samples_per_second\n",
    "    videonr = 0\n",
    "\n",
    "    for start, end in intervals:\n",
    "        idx = np.where((timestamps >= start) & (timestamps < end))[0]\n",
    "\n",
    "        if len(idx) < int(sampling_rate*5):\n",
    "            print(f\"Skipping interval ({start}, {end}) — not enough data.\")\n",
    "            continue\n",
    "\n",
    "        segment = ecg_data[idx]\n",
    "\n",
    "        try:\n",
    "            signals, info = nk.ecg_process(segment, sampling_rate=sampling_rate)\n",
    "            rpeaks = info[\"ECG_R_Peaks\"]\n",
    "\n",
    "            if len(rpeaks) < 2:\n",
    "                print(f\"Skipping interval ({start}-{end}) — not enough R-peaks.\")\n",
    "                continue\n",
    "\n",
    "            # Time-domain metrics\n",
    "            print(f\"Interval ({start}-{end}): {len(rpeaks)} R-peaks detected\")\n",
    "            try:\n",
    "                time_features = nk.hrv_time(rpeaks, sampling_rate=sampling_rate, show=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Time HRV failed: {e}\")\n",
    "                time_features = pd.DataFrame()\n",
    "            # Frequency-domain metrics\n",
    "            try:\n",
    "                welch_results = pyhrv.frequency_domain.welch_psd(rpeaks, show=False)\n",
    "                lf_hf_ratio_pyhrv = float(welch_results[\"fft_ratio\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Frequency HRV failed: {e}\")\n",
    "                freq_features = pd.DataFrame()\n",
    "\n",
    "            # Use .get() with default values\n",
    "            for x in range(group_size):\n",
    "                results3.append({\n",
    "                    \"participant\" : participant,\n",
    "                    \"videonr\" : videonr,\n",
    "                    \"Start Time (s) 60s\": start,\n",
    "                    \"End Time (s) 60s\": end,\n",
    "                    \"RMSSD_6\": time_features.get(\"HRV_RMSSD\", [np.nan])[0],\n",
    "                    \"SDSD_6\": time_features.get(\"HRV_SDSD\", [np.nan])[0],\n",
    "                    \"LF/HF_6\": lf_hf_ratio_pyhrv\n",
    "                })\n",
    "                videonr = videonr + 1\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process interval ({start}-{end}): {e}\")\n",
    "            continue\n",
    "'''"
   ],
   "id": "3f19440a4a413160",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "results1_df = pd.DataFrame(results1)\n",
    "results2_df = pd.DataFrame(results2)\n",
    "results3_df = pd.DataFrame(results3)\n",
    "# Merge results1_df and results2_df\n",
    "merged_df = pd.merge(\n",
    "    results1_df,\n",
    "    results2_df,\n",
    "    on=['participant', 'videonr'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Merge the result with results3_df\n",
    "df_results = pd.merge(\n",
    "    merged_df,\n",
    "    results3_df,\n",
    "    on=['participant', 'videonr'],\n",
    "    how='inner'\n",
    ")\n",
    "df_results.to_csv(\"hrv_all.csv\", index=False)\n",
    "results1_df.to_csv(\"hrv_1.csv\", index=False)\n",
    "results2_df.to_csv(\"hrv_3.csv\", index=False)\n",
    "'''\n"
   ],
   "id": "81e1ea924b2b38f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results1_df = pd.DataFrame(results1)\n",
    "results2_df = pd.DataFrame(results2)\n",
    "# Merge results1_df and results2_df\n",
    "merged_df = pd.merge(\n",
    "    results1_df,\n",
    "    results2_df,\n",
    "    on=['participant', 'videonr'],\n",
    "    how='inner'\n",
    ")\n",
    "merged_df.to_csv(\"hrv_all.csv\", index=False)\n",
    "results1_df.to_csv(\"hrv_1.csv\", index=False)\n",
    "results2_df.to_csv(\"hrv_3.csv\", index=False)"
   ],
   "id": "a47be5f2b14ff3e6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
